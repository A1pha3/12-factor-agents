[← 智能体的承诺](agent-promise.md)

# "循环直到解决"模式的问题

## 这种"循环直到解决"模式的问题

这种模式的最大问题：

- 当上下文窗口变得太长时，智能体会迷失方向 - 它们会陷入尝试相同破损方法的循环中
- 字面上就是这样，但这足以削弱这种方法

即使你没有手工制作智能体，你可能在使用智能体编码工具时也见过这种长上下文问题。它们在一段时间后就会迷失，你需要开始新的聊天。

我甚至可能提出一些我经常听到的观点，你可能也已经形成了自己的直觉：

> ### **即使模型支持越来越长的上下文窗口，你总是会通过小而专注的提示词和上下文获得更好的结果**

我交谈过的大多数构建者在意识到超过10-20轮的任何事情都会变成大语言模型无法恢复的大混乱时，都**将"工具调用循环"的想法推到一边**。即使智能体90%的时间都做对了，这也远远达不到"足够好到可以放在客户手中"。你能想象一个在10%的页面加载时崩溃的网络应用吗？

**2025-06-09更新** - 我真的很喜欢[@swyx](https://x.com/swyx/status/1932125643384455237)的表述：

<a href="https://x.com/swyx/status/1932125643384455237"><img width="593" alt="Screenshot 2025-07-02 at 11 50 50 AM" src="https://github.com/user-attachments/assets/c7d94042-e4b9-4b87-87fd-55c7ff94bb3b" /></a>

## 真正有效的方法 - 微智能体

我在实际应用中**确实**看到很多的一件事是采用智能体模式并将其撒入更广泛的更确定性的DAG中。

![micro-agent-dag](../../img/028-micro-agent-dag.png)

你可能会问 - "在这种情况下为什么要使用智能体？" - 我们很快就会讨论这个，但基本上，让语言模型管理范围明确的任务集合，使得很容易整合实时人类反馈，将其转化为工作流步骤，而不会陷入上下文错误循环。（[因子1](../factors/factor-01-natural-language-to-tool-calls.md)、[因子3](../factors/factor-03-own-your-context-window.md)、[因子7](../factors/factor-07-contact-humans-with-tools.md)）。

> #### 让语言模型管理范围明确的任务集合，使得很容易整合实时人类反馈...而不会陷入上下文错误循环

[真实的微智能体示例 →](micro-agent-example.md)