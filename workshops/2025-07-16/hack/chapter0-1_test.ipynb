{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be04e2a1",
   "metadata": {},
   "source": [
    "# Building the 12-factor agent template from scratch in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd951167",
   "metadata": {},
   "source": [
    "Steps to start from a bare Python repo and build up a 12-factor agent. This walkthrough will guide you through creating a Python agent that follows the 12-factor methodology with BAML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8bd795",
   "metadata": {},
   "source": [
    "## Chapter 0 - Hello World"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65edc632",
   "metadata": {},
   "source": [
    "Let's start with a basic Python setup and a hello world program."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349851d1",
   "metadata": {},
   "source": [
    "This guide will walk you through building agents in Python with BAML.\n",
    "\n",
    "We'll start simple with a hello world program and gradually build up to a full agent.\n",
    "\n",
    "For this notebook, you'll need to have your OpenAI API key saved in Google Colab secrets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c54be5",
   "metadata": {},
   "source": [
    "Here's our simple hello world program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce40eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./walkthrough/00-main.py\n",
    "def hello():\n",
    "    print('hello, world!')\n",
    "\n",
    "def main():\n",
    "    hello()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5adaf8",
   "metadata": {},
   "source": [
    "Let's run it to verify it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5068756a",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f75943",
   "metadata": {},
   "source": [
    "## Chapter 1 - CLI and Agent Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a41e811",
   "metadata": {},
   "source": [
    "Now let's add BAML and create our first agent with a CLI interface."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f390af8c",
   "metadata": {},
   "source": [
    "In this chapter, we'll integrate BAML to create an AI agent that can respond to user input.\n",
    "\n",
    "First, let's set up BAML support in our notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3cf8ff",
   "metadata": {},
   "source": [
    "### BAML Setup\n",
    "\n",
    "Don't worry too much about this setup code - it will make sense later! For now, just know that:\n",
    "- BAML is a tool for working with language models\n",
    "- We need some special setup code to make it work nicely in Google Colab\n",
    "- The `get_baml_client()` function will be used to interact with AI models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6787b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install baml-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a87bf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from google.colab import userdata\n",
    "import os\n",
    "\n",
    "def baml_generate():\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"baml-cli\", \"generate\"],\n",
    "            check=True,\n",
    "            capture_output=True,\n",
    "            text=True\n",
    "        )\n",
    "        if result.stdout:\n",
    "            print(\"[baml-cli generate]\\n\", result.stdout)\n",
    "        if result.stderr:\n",
    "            print(\"[baml-cli generate]\\n\", result.stderr)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        msg = (\n",
    "            f\"`baml-cli generate` failed with exit code {e.returncode}\\n\"\n",
    "            f\"--- STDOUT ---\\n{e.stdout}\\n\"\n",
    "            f\"--- STDERR ---\\n{e.stderr}\"\n",
    "        )\n",
    "        raise RuntimeError(msg) from None\n",
    "\n",
    "def get_baml_client():\n",
    "    \"\"\"\n",
    "    a bunch of fun jank to work around the google colab import cache\n",
    "    \"\"\"\n",
    "    os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
    "    \n",
    "    baml_generate()\n",
    "    \n",
    "    import importlib\n",
    "    import baml_client\n",
    "    importlib.reload(baml_client)\n",
    "    return baml_client.sync_client.b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59b175f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!baml-cli init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a0e941",
   "metadata": {},
   "source": [
    "Now let's create our agent that will use BAML to process user input.\n",
    "\n",
    "First, we'll define the core agent logic:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70570b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./walkthrough/01-agent.py\n",
    "import json\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "# tool call or a respond to human tool\n",
    "AgentResponse = Any  # This will be the return type from b.DetermineNextStep\n",
    "\n",
    "class Event:\n",
    "    def __init__(self, type: str, data: Any):\n",
    "        self.type = type\n",
    "        self.data = data\n",
    "\n",
    "class Thread:\n",
    "    def __init__(self, events: List[Dict[str, Any]]):\n",
    "        self.events = events\n",
    "    \n",
    "    def serialize_for_llm(self):\n",
    "        # can change this to whatever custom serialization you want to do, XML, etc\n",
    "        # e.g. https://github.com/got-agents/agents/blob/59ebbfa236fc376618f16ee08eb0f3bf7b698892/linear-assistant-ts/src/agent.ts#L66-L105\n",
    "        return json.dumps(self.events)\n",
    "\n",
    "# right now this just runs one turn with the LLM, but\n",
    "# we'll update this function to handle all the agent logic\n",
    "def agent_loop(thread: Thread) -> AgentResponse:\n",
    "    b = get_baml_client()  # This will be defined by the BAML setup\n",
    "    next_step = b.DetermineNextStep(thread.serialize_for_llm())\n",
    "    return next_step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9ef001",
   "metadata": {},
   "source": [
    "Next, we need to define the BAML function that our agent will use.\n",
    "\n",
    "This BAML file defines what our agent can do:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d1ffc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -fsSL -o baml_src/01-agent.baml https://raw.githubusercontent.com/humanlayer/12-factor-agents/refs/heads/main/workshops/2025-07-16/./walkthrough/01-agent.baml && cat baml_src/01-agent.baml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf84ac22",
   "metadata": {},
   "source": [
    "Now let's create our main function that simulates command-line arguments:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430d840b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./walkthrough/01-main.py\n",
    "import sys\n",
    "\n",
    "def main():\n",
    "    # Set default args if none provided\n",
    "    if len(sys.argv) < 2:\n",
    "        sys.argv = [\"notebook\", \"hello from the notebook!\"]\n",
    "    \n",
    "    # Get command line arguments, skipping the first one (script name)\n",
    "    args = sys.argv[1:]\n",
    "    \n",
    "    if len(args) == 0:\n",
    "        print(\"Error: Please provide a message as a command line argument\", file=sys.stderr)\n",
    "        return\n",
    "    \n",
    "    # Join all arguments into a single message\n",
    "    message = \" \".join(args)\n",
    "    \n",
    "    # Create a new thread with the user's message as the initial event\n",
    "    thread = Thread([{\"type\": \"user_input\", \"data\": message}])\n",
    "    \n",
    "    # Run the agent loop with the thread\n",
    "    result = agent_loop(thread)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938ca8b7",
   "metadata": {},
   "source": [
    "Let's test our agent! You can modify the sys.argv line in the cell above to send different messages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea2980e",
   "metadata": {},
   "outputs": [],
   "source": [
    "baml_generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a10500c",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
